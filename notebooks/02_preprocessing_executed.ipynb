{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Data Preprocessing & Feature Engineering\n",
    "\n",
    "This notebook handles data preprocessing including:\n",
    "- Missing value handling\n",
    "- Skills multi-hot encoding with frequency filtering\n",
    "- Categorical encoding (ordinal and one-hot)\n",
    "- Feature scaling\n",
    "- Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-23T12:41:24.906626Z",
     "iopub.status.busy": "2026-02-23T12:41:24.906415Z",
     "iopub.status.idle": "2026-02-23T12:41:26.094284Z",
     "shell.execute_reply": "2026-02-23T12:41:26.093997Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-23T12:41:26.095538Z",
     "iopub.status.busy": "2026-02-23T12:41:26.095416Z",
     "iopub.status.idle": "2026-02-23T12:41:26.122557Z",
     "shell.execute_reply": "2026-02-23T12:41:26.122329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: (15000, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary_usd</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>required_skills</th>\n",
       "      <th>education_required</th>\n",
       "      <th>years_experience</th>\n",
       "      <th>industry</th>\n",
       "      <th>posting_date</th>\n",
       "      <th>application_deadline</th>\n",
       "      <th>job_description_length</th>\n",
       "      <th>benefits_score</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AI00001</td>\n",
       "      <td>AI Research Scientist</td>\n",
       "      <td>90376</td>\n",
       "      <td>USD</td>\n",
       "      <td>SE</td>\n",
       "      <td>CT</td>\n",
       "      <td>China</td>\n",
       "      <td>M</td>\n",
       "      <td>China</td>\n",
       "      <td>50</td>\n",
       "      <td>Tableau, PyTorch, Kubernetes, Linux, NLP</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>9</td>\n",
       "      <td>Automotive</td>\n",
       "      <td>2024-10-18</td>\n",
       "      <td>2024-11-07</td>\n",
       "      <td>1076</td>\n",
       "      <td>5.9</td>\n",
       "      <td>Smart Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AI00002</td>\n",
       "      <td>AI Software Engineer</td>\n",
       "      <td>61895</td>\n",
       "      <td>USD</td>\n",
       "      <td>EN</td>\n",
       "      <td>CT</td>\n",
       "      <td>Canada</td>\n",
       "      <td>M</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>100</td>\n",
       "      <td>Deep Learning, AWS, Mathematics, Python, Docker</td>\n",
       "      <td>Master</td>\n",
       "      <td>1</td>\n",
       "      <td>Media</td>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>2025-01-11</td>\n",
       "      <td>1268</td>\n",
       "      <td>5.2</td>\n",
       "      <td>TechCorp Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AI00003</td>\n",
       "      <td>AI Specialist</td>\n",
       "      <td>152626</td>\n",
       "      <td>USD</td>\n",
       "      <td>MI</td>\n",
       "      <td>FL</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>L</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>0</td>\n",
       "      <td>Kubernetes, Deep Learning, Java, Hadoop, NLP</td>\n",
       "      <td>Associate</td>\n",
       "      <td>2</td>\n",
       "      <td>Education</td>\n",
       "      <td>2025-03-18</td>\n",
       "      <td>2025-04-07</td>\n",
       "      <td>1974</td>\n",
       "      <td>9.4</td>\n",
       "      <td>Autonomous Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AI00004</td>\n",
       "      <td>NLP Engineer</td>\n",
       "      <td>80215</td>\n",
       "      <td>USD</td>\n",
       "      <td>SE</td>\n",
       "      <td>FL</td>\n",
       "      <td>India</td>\n",
       "      <td>M</td>\n",
       "      <td>India</td>\n",
       "      <td>50</td>\n",
       "      <td>Scala, SQL, Linux, Python</td>\n",
       "      <td>PhD</td>\n",
       "      <td>7</td>\n",
       "      <td>Consulting</td>\n",
       "      <td>2024-12-23</td>\n",
       "      <td>2025-02-24</td>\n",
       "      <td>1345</td>\n",
       "      <td>8.6</td>\n",
       "      <td>Future Systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI00005</td>\n",
       "      <td>AI Consultant</td>\n",
       "      <td>54624</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EN</td>\n",
       "      <td>PT</td>\n",
       "      <td>France</td>\n",
       "      <td>S</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>100</td>\n",
       "      <td>MLOps, Java, Tableau, Python</td>\n",
       "      <td>Master</td>\n",
       "      <td>0</td>\n",
       "      <td>Media</td>\n",
       "      <td>2025-04-15</td>\n",
       "      <td>2025-06-23</td>\n",
       "      <td>1989</td>\n",
       "      <td>6.6</td>\n",
       "      <td>Advanced Robotics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    job_id              job_title  salary_usd salary_currency  \\\n",
       "0  AI00001  AI Research Scientist       90376             USD   \n",
       "1  AI00002   AI Software Engineer       61895             USD   \n",
       "2  AI00003          AI Specialist      152626             USD   \n",
       "3  AI00004           NLP Engineer       80215             USD   \n",
       "4  AI00005          AI Consultant       54624             EUR   \n",
       "\n",
       "  experience_level employment_type company_location company_size  \\\n",
       "0               SE              CT            China            M   \n",
       "1               EN              CT           Canada            M   \n",
       "2               MI              FL      Switzerland            L   \n",
       "3               SE              FL            India            M   \n",
       "4               EN              PT           France            S   \n",
       "\n",
       "  employee_residence  remote_ratio  \\\n",
       "0              China            50   \n",
       "1            Ireland           100   \n",
       "2        South Korea             0   \n",
       "3              India            50   \n",
       "4          Singapore           100   \n",
       "\n",
       "                                   required_skills education_required  \\\n",
       "0         Tableau, PyTorch, Kubernetes, Linux, NLP           Bachelor   \n",
       "1  Deep Learning, AWS, Mathematics, Python, Docker             Master   \n",
       "2     Kubernetes, Deep Learning, Java, Hadoop, NLP          Associate   \n",
       "3                        Scala, SQL, Linux, Python                PhD   \n",
       "4                     MLOps, Java, Tableau, Python             Master   \n",
       "\n",
       "   years_experience    industry posting_date application_deadline  \\\n",
       "0                 9  Automotive   2024-10-18           2024-11-07   \n",
       "1                 1       Media   2024-11-20           2025-01-11   \n",
       "2                 2   Education   2025-03-18           2025-04-07   \n",
       "3                 7  Consulting   2024-12-23           2025-02-24   \n",
       "4                 0       Media   2025-04-15           2025-06-23   \n",
       "\n",
       "   job_description_length  benefits_score       company_name  \n",
       "0                    1076             5.9    Smart Analytics  \n",
       "1                    1268             5.2       TechCorp Inc  \n",
       "2                    1974             9.4    Autonomous Tech  \n",
       "3                    1345             8.6     Future Systems  \n",
       "4                    1989             6.6  Advanced Robotics  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/ai_job_dataset.csv')\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Select Features & Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-23T12:41:26.135744Z",
     "iopub.status.busy": "2026-02-23T12:41:26.135617Z",
     "iopub.status.idle": "2026-02-23T12:41:26.138113Z",
     "shell.execute_reply": "2026-02-23T12:41:26.137918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working dataset shape: (15000, 12)\n",
      "\n",
      "Columns: ['job_title', 'salary_usd', 'experience_level', 'employment_type', 'company_location', 'company_size', 'remote_ratio', 'required_skills', 'education_required', 'years_experience', 'industry', 'benefits_score']\n"
     ]
    }
   ],
   "source": [
    "# Columns to drop (identifiers, leakage-prone, low predictive value)\n",
    "drop_cols = ['job_id', 'salary_currency', 'employee_residence', 'posting_date', \n",
    "             'application_deadline', 'job_description_length', 'company_name']\n",
    "\n",
    "# Target variable\n",
    "target = 'salary_usd'\n",
    "\n",
    "# Create working dataframe\n",
    "df_work = df.drop(columns=drop_cols)\n",
    "print(f\"Working dataset shape: {df_work.shape}\")\n",
    "print(f\"\\nColumns: {df_work.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Missing Value Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-23T12:41:26.139192Z",
     "iopub.status.busy": "2026-02-23T12:41:26.139108Z",
     "iopub.status.idle": "2026-02-23T12:41:26.143446Z",
     "shell.execute_reply": "2026-02-23T12:41:26.143236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values summary:\n",
      "Empty DataFrame\n",
      "Columns: [Missing Count, Missing %]\n",
      "Index: []\n",
      "\n",
      "No missing values found!\n"
     ]
    }
   ],
   "source": [
    "# Check missing values\n",
    "missing = df_work.isnull().sum()\n",
    "missing_pct = (missing / len(df_work)) * 100\n",
    "missing_df = pd.DataFrame({'Missing Count': missing, 'Missing %': missing_pct})\n",
    "print(\"Missing values summary:\")\n",
    "print(missing_df[missing_df['Missing Count'] > 0].sort_values('Missing %', ascending=False))\n",
    "\n",
    "if missing.sum() == 0:\n",
    "    print(\"\\nNo missing values found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Outlier Handling (IQR-Based Capping)\n",
    "\n",
    "Cap extreme salary values using the IQR method (winsorization) to reduce the impact of outliers without dropping rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-23T12:41:26.144349Z",
     "iopub.status.busy": "2026-02-23T12:41:26.144294Z",
     "iopub.status.idle": "2026-02-23T12:41:26.148189Z",
     "shell.execute_reply": "2026-02-23T12:41:26.148003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary IQR bounds: [-44,163, 260,752]\n",
      "Outliers below: 0, above: 483\n",
      "\n",
      "After capping:\n",
      "count     15000.000000\n",
      "mean     114125.066192\n",
      "std       56554.408273\n",
      "min       32519.000000\n",
      "25%       70179.750000\n",
      "50%       99705.000000\n",
      "75%      146408.500000\n",
      "max      260751.625000\n",
      "Name: salary_usd, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# IQR-based winsorization on salary_usd\n",
    "Q1 = df_work['salary_usd'].quantile(0.25)\n",
    "Q3 = df_work['salary_usd'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers_below = (df_work['salary_usd'] < lower_bound).sum()\n",
    "outliers_above = (df_work['salary_usd'] > upper_bound).sum()\n",
    "print(f\"Salary IQR bounds: [{lower_bound:,.0f}, {upper_bound:,.0f}]\")\n",
    "print(f\"Outliers below: {outliers_below}, above: {outliers_above}\")\n",
    "\n",
    "# Cap (winsorize) instead of dropping\n",
    "df_work['salary_usd'] = df_work['salary_usd'].clip(lower=lower_bound, upper=upper_bound)\n",
    "print(f\"\\nAfter capping:\")\n",
    "print(df_work['salary_usd'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Salary Log-Transform\n",
    "\n",
    "Apply `log1p` to normalize the right-skewed salary distribution. Models will be trained on log-scale; predictions will be inverse-transformed back to dollars for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-23T12:41:26.149146Z",
     "iopub.status.busy": "2026-02-23T12:41:26.149070Z",
     "iopub.status.idle": "2026-02-23T12:41:26.151388Z",
     "shell.execute_reply": "2026-02-23T12:41:26.151196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary distribution before and after log transform:\n",
      "  salary_usd  — skew: 0.937, mean: $114,125\n",
      "  salary_log  — skew: 0.053, mean: 11.5274\n"
     ]
    }
   ],
   "source": [
    "# Apply log1p transform to salary\n",
    "df_work['salary_log'] = np.log1p(df_work['salary_usd'])\n",
    "\n",
    "print(\"Salary distribution before and after log transform:\")\n",
    "print(f\"  salary_usd  — skew: {df_work['salary_usd'].skew():.3f}, mean: ${df_work['salary_usd'].mean():,.0f}\")\n",
    "print(f\"  salary_log  — skew: {df_work['salary_log'].skew():.3f}, mean: {df_work['salary_log'].mean():.4f}\")\n",
    "\n",
    "# Keep original salary for later inverse-transform evaluation\n",
    "df_work['salary_original'] = df_work['salary_usd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Skills Multi-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-23T12:41:26.152388Z",
     "iopub.status.busy": "2026-02-23T12:41:26.152305Z",
     "iopub.status.idle": "2026-02-23T12:41:26.161399Z",
     "shell.execute_reply": "2026-02-23T12:41:26.161205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique skills: 24\n",
      "\n",
      "Skill frequency distribution:\n",
      "count      24.000000\n",
      "mean     2495.541667\n",
      "std       572.221603\n",
      "min      1833.000000\n",
      "25%      2152.500000\n",
      "50%      2326.000000\n",
      "75%      2723.000000\n",
      "max      4450.000000\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Extract all unique skills and their frequencies\n",
    "def extract_skills(df):\n",
    "    all_skills = []\n",
    "    for skills_str in df['required_skills']:\n",
    "        skills = [s.strip() for s in skills_str.split(',')]\n",
    "        all_skills.extend(skills)\n",
    "    return pd.Series(all_skills).value_counts()\n",
    "\n",
    "skill_counts = extract_skills(df_work)\n",
    "print(f\"Total unique skills: {len(skill_counts)}\")\n",
    "print(f\"\\nSkill frequency distribution:\")\n",
    "print(skill_counts.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-23T12:41:26.162402Z",
     "iopub.status.busy": "2026-02-23T12:41:26.162343Z",
     "iopub.status.idle": "2026-02-23T12:41:26.164003Z",
     "shell.execute_reply": "2026-02-23T12:41:26.163825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills appearing in >= 2% of samples: 24\n",
      "Frequent skills: ['Python', 'SQL', 'TensorFlow', 'Kubernetes', 'Scala', 'PyTorch', 'Linux', 'Git', 'Java', 'GCP', 'Hadoop', 'Tableau', 'R', 'Computer Vision', 'Data Visualization', 'Deep Learning', 'MLOps', 'Spark', 'NLP', 'Azure', 'AWS', 'Mathematics', 'Docker', 'Statistics']\n"
     ]
    }
   ],
   "source": [
    "# Filter skills that appear in at least 2% of samples\n",
    "min_freq = 0.02 * len(df_work)\n",
    "frequent_skills = skill_counts[skill_counts >= min_freq].index.tolist()\n",
    "print(f\"Skills appearing in >= 2% of samples: {len(frequent_skills)}\")\n",
    "print(f\"Frequent skills: {frequent_skills}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-23T12:41:26.164780Z",
     "iopub.status.busy": "2026-02-23T12:41:26.164731Z",
     "iopub.status.idle": "2026-02-23T12:41:26.292845Z",
     "shell.execute_reply": "2026-02-23T12:41:26.292623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills encoded shape: (15000, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill_python</th>\n",
       "      <th>skill_sql</th>\n",
       "      <th>skill_tensorflow</th>\n",
       "      <th>skill_kubernetes</th>\n",
       "      <th>skill_scala</th>\n",
       "      <th>skill_pytorch</th>\n",
       "      <th>skill_linux</th>\n",
       "      <th>skill_git</th>\n",
       "      <th>skill_java</th>\n",
       "      <th>skill_gcp</th>\n",
       "      <th>skill_hadoop</th>\n",
       "      <th>skill_tableau</th>\n",
       "      <th>skill_r</th>\n",
       "      <th>skill_computer_vision</th>\n",
       "      <th>skill_data_visualization</th>\n",
       "      <th>skill_deep_learning</th>\n",
       "      <th>skill_mlops</th>\n",
       "      <th>skill_spark</th>\n",
       "      <th>skill_nlp</th>\n",
       "      <th>skill_azure</th>\n",
       "      <th>skill_aws</th>\n",
       "      <th>skill_mathematics</th>\n",
       "      <th>skill_docker</th>\n",
       "      <th>skill_statistics</th>\n",
       "      <th>other_skills_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   skill_python  skill_sql  skill_tensorflow  skill_kubernetes  skill_scala  \\\n",
       "0             0          0                 0                 1            0   \n",
       "1             1          0                 0                 0            0   \n",
       "2             0          0                 0                 1            0   \n",
       "3             1          1                 0                 0            1   \n",
       "4             1          0                 0                 0            0   \n",
       "\n",
       "   skill_pytorch  skill_linux  skill_git  skill_java  skill_gcp  skill_hadoop  \\\n",
       "0              1            1          0           0          0             0   \n",
       "1              0            0          0           0          0             0   \n",
       "2              0            0          0           1          0             1   \n",
       "3              0            1          0           0          0             0   \n",
       "4              0            0          0           1          0             0   \n",
       "\n",
       "   skill_tableau  skill_r  skill_computer_vision  skill_data_visualization  \\\n",
       "0              1        0                      0                         0   \n",
       "1              0        0                      0                         0   \n",
       "2              0        0                      0                         0   \n",
       "3              0        0                      0                         0   \n",
       "4              1        0                      0                         0   \n",
       "\n",
       "   skill_deep_learning  skill_mlops  skill_spark  skill_nlp  skill_azure  \\\n",
       "0                    0            0            0          1            0   \n",
       "1                    1            0            0          0            0   \n",
       "2                    1            0            0          1            0   \n",
       "3                    0            0            0          0            0   \n",
       "4                    0            1            0          0            0   \n",
       "\n",
       "   skill_aws  skill_mathematics  skill_docker  skill_statistics  \\\n",
       "0          0                  0             0                 0   \n",
       "1          1                  1             1                 0   \n",
       "2          0                  0             0                 0   \n",
       "3          0                  0             0                 0   \n",
       "4          0                  0             0                 0   \n",
       "\n",
       "   other_skills_count  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_skills(df, frequent_skills):\n",
    "    \"\"\"\n",
    "    Multi-hot encode skills.\n",
    "    Returns a DataFrame with binary columns for each frequent skill,\n",
    "    plus a count of rare skills.\n",
    "    \"\"\"\n",
    "    skill_matrix = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    for skill in frequent_skills:\n",
    "        skill_col = f\"skill_{skill.replace(' ', '_').replace('-', '_').lower()}\"\n",
    "        skill_matrix[skill_col] = df['required_skills'].apply(\n",
    "            lambda x: 1 if skill in [s.strip() for s in x.split(',')] else 0\n",
    "        )\n",
    "    \n",
    "    # Count rare skills (those not in frequent_skills)\n",
    "    def count_rare_skills(skills_str):\n",
    "        skills = [s.strip() for s in skills_str.split(',')]\n",
    "        rare_count = sum(1 for s in skills if s not in frequent_skills)\n",
    "        return rare_count\n",
    "    \n",
    "    skill_matrix['other_skills_count'] = df['required_skills'].apply(count_rare_skills)\n",
    "    \n",
    "    return skill_matrix\n",
    "\n",
    "# Encode skills\n",
    "skills_encoded = encode_skills(df_work, frequent_skills)\n",
    "print(f\"Skills encoded shape: {skills_encoded.shape}\")\n",
    "skills_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-23T12:41:26.293820Z",
     "iopub.status.busy": "2026-02-23T12:41:26.293758Z",
     "iopub.status.idle": "2026-02-23T12:41:26.299663Z",
     "shell.execute_reply": "2026-02-23T12:41:26.299446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experience level encoding:\n",
      "   experience_level  experience_level_enc\n",
      "1                EN                     0\n",
      "2                MI                     1\n",
      "0                SE                     2\n",
      "11               EX                     3\n",
      "\n",
      "Education encoding:\n",
      "  education_required  education_required_enc\n",
      "2          Associate                       0\n",
      "0           Bachelor                       1\n",
      "1             Master                       2\n",
      "3                PhD                       3\n"
     ]
    }
   ],
   "source": [
    "# Define ordinal mappings\n",
    "experience_order = ['EN', 'MI', 'SE', 'EX']  # Entry -> Executive\n",
    "education_order = ['Associate', 'Bachelor', 'Master', 'PhD']  # Low -> High\n",
    "\n",
    "# Apply ordinal encoding\n",
    "df_work['experience_level_enc'] = df_work['experience_level'].map(\n",
    "    {v: i for i, v in enumerate(experience_order)}\n",
    ")\n",
    "df_work['education_required_enc'] = df_work['education_required'].map(\n",
    "    {v: i for i, v in enumerate(education_order)}\n",
    ")\n",
    "\n",
    "print(\"Experience level encoding:\")\n",
    "print(df_work[['experience_level', 'experience_level_enc']].drop_duplicates().sort_values('experience_level_enc'))\n",
    "print(\"\\nEducation encoding:\")\n",
    "print(df_work[['education_required', 'education_required_enc']].drop_duplicates().sort_values('education_required_enc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. One-Hot Encoding for Nominal Categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-23T12:41:26.300696Z",
     "iopub.status.busy": "2026-02-23T12:41:26.300638Z",
     "iopub.status.idle": "2026-02-23T12:41:26.307326Z",
     "shell.execute_reply": "2026-02-23T12:41:26.307113Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded shape: (15000, 65)\n",
      "One-hot columns: ['job_title_AI Architect', 'job_title_AI Consultant', 'job_title_AI Product Manager', 'job_title_AI Research Scientist', 'job_title_AI Software Engineer', 'job_title_AI Specialist', 'job_title_Autonomous Systems Engineer', 'job_title_Computer Vision Engineer', 'job_title_Data Analyst', 'job_title_Data Engineer']...\n"
     ]
    }
   ],
   "source": [
    "# Columns to one-hot encode\n",
    "onehot_cols = ['job_title', 'company_location', 'industry', 'employment_type', 'company_size']\n",
    "\n",
    "# Convert remote_ratio to categorical (it's essentially categorical)\n",
    "df_work['remote_ratio'] = df_work['remote_ratio'].astype(str)\n",
    "onehot_cols.append('remote_ratio')\n",
    "\n",
    "# One-hot encode\n",
    "df_onehot = pd.get_dummies(df_work[onehot_cols], prefix=onehot_cols, drop_first=False)\n",
    "print(f\"One-hot encoded shape: {df_onehot.shape}\")\n",
    "print(f\"One-hot columns: {df_onehot.columns.tolist()[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Combine All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-23T12:41:26.308335Z",
     "iopub.status.busy": "2026-02-23T12:41:26.308264Z",
     "iopub.status.idle": "2026-02-23T12:41:26.311240Z",
     "shell.execute_reply": "2026-02-23T12:41:26.311086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature matrix shape: (15000, 94)\n",
      "Target shape (log-scale): (15000,)\n",
      "Target shape (original $): (15000,)\n"
     ]
    }
   ],
   "source": [
    "# Numerical features\n",
    "numerical_cols = ['years_experience', 'benefits_score']\n",
    "\n",
    "# Ordinal encoded features\n",
    "ordinal_cols = ['experience_level_enc', 'education_required_enc']\n",
    "\n",
    "# Combine all features\n",
    "X = pd.concat([\n",
    "    df_work[numerical_cols],\n",
    "    df_work[ordinal_cols],\n",
    "    df_onehot,\n",
    "    skills_encoded\n",
    "], axis=1)\n",
    "\n",
    "# Use log-transformed salary as target for training\n",
    "y = df_work['salary_log']\n",
    "\n",
    "# Keep original-scale salary for evaluation\n",
    "y_original = df_work['salary_original']\n",
    "\n",
    "print(f\"Final feature matrix shape: {X.shape}\")\n",
    "print(f\"Target shape (log-scale): {y.shape}\")\n",
    "print(f\"Target shape (original $): {y_original.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-23T12:41:26.312132Z",
     "iopub.status.busy": "2026-02-23T12:41:26.312078Z",
     "iopub.status.idle": "2026-02-23T12:41:26.313627Z",
     "shell.execute_reply": "2026-02-23T12:41:26.313445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature categories:\n",
      "  - Numerical: 2 features\n",
      "  - Ordinal encoded: 2 features\n",
      "  - One-hot encoded: 65 features\n",
      "  - Skills encoded: 25 features\n",
      "  - Total: 94 features\n"
     ]
    }
   ],
   "source": [
    "# Display feature summary\n",
    "print(\"Feature categories:\")\n",
    "print(f\"  - Numerical: {len(numerical_cols)} features\")\n",
    "print(f\"  - Ordinal encoded: {len(ordinal_cols)} features\")\n",
    "print(f\"  - One-hot encoded: {df_onehot.shape[1]} features\")\n",
    "print(f\"  - Skills encoded: {skills_encoded.shape[1]} features\")\n",
    "print(f\"  - Total: {X.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train / Validation / Test Split (70/10/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-23T12:41:26.314519Z",
     "iopub.status.busy": "2026-02-23T12:41:26.314466Z",
     "iopub.status.idle": "2026-02-23T12:41:26.326617Z",
     "shell.execute_reply": "2026-02-23T12:41:26.326422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:   10500 samples (70%)\n",
      "Validation set: 1500 samples (10%)\n",
      "Test set:       3000 samples (20%)\n",
      "\n",
      "Target (log-scale) distribution in training set:\n",
      "count    10500.000000\n",
      "mean        11.527512\n",
      "std          0.486874\n",
      "min         10.390318\n",
      "25%         11.159178\n",
      "50%         11.508636\n",
      "75%         11.893958\n",
      "max         12.471327\n",
      "Name: salary_log, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Two-stage split: first 70/30, then split the 30 into 10 val + 20 test\n",
    "strat_col = df_work['experience_level']\n",
    "\n",
    "# Stage 1: 70% train, 30% temp\n",
    "X_train, X_temp, y_train, y_temp, strat_train, strat_temp = train_test_split(\n",
    "    X, y, strat_col,\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    "    stratify=strat_col\n",
    ")\n",
    "\n",
    "# Also split original-scale targets in parallel\n",
    "y_train_original = y_original.loc[X_train.index]\n",
    "y_temp_original = y_original.loc[X_temp.index]\n",
    "\n",
    "# Stage 2: split 30% into 1/3 val (10% overall) + 2/3 test (20% overall)\n",
    "X_val, X_test, y_val, y_test, strat_val, strat_test = train_test_split(\n",
    "    X_temp, y_temp, strat_temp,\n",
    "    test_size=2/3,\n",
    "    random_state=42,\n",
    "    stratify=strat_temp\n",
    ")\n",
    "\n",
    "y_val_original = y_temp_original.loc[X_val.index]\n",
    "y_test_original = y_temp_original.loc[X_test.index]\n",
    "\n",
    "print(f\"Training set:   {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.0f}%)\")\n",
    "print(f\"Validation set: {X_val.shape[0]} samples ({X_val.shape[0]/len(X)*100:.0f}%)\")\n",
    "print(f\"Test set:       {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.0f}%)\")\n",
    "print(f\"\\nTarget (log-scale) distribution in training set:\")\n",
    "print(y_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-23T12:41:26.327623Z",
     "iopub.status.busy": "2026-02-23T12:41:26.327546Z",
     "iopub.status.idle": "2026-02-23T12:41:26.332000Z",
     "shell.execute_reply": "2026-02-23T12:41:26.331812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling applied to: ['years_experience', 'benefits_score', 'other_skills_count']\n",
      "\n",
      "Scaled training data sample statistics for 'years_experience':\n",
      "  Mean: -0.0000\n",
      "  Std: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Scale numerical features (for linear models and MLP)\n",
    "# Tree-based models don't need scaling, but we'll create scaled version anyway\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Columns to scale\n",
    "cols_to_scale = numerical_cols + ['other_skills_count']\n",
    "\n",
    "# Fit scaler on training data only\n",
    "X_train_scaled = X_train.copy()\n",
    "X_val_scaled = X_val.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_train_scaled[cols_to_scale] = scaler.fit_transform(X_train[cols_to_scale])\n",
    "X_val_scaled[cols_to_scale] = scaler.transform(X_val[cols_to_scale])\n",
    "X_test_scaled[cols_to_scale] = scaler.transform(X_test[cols_to_scale])\n",
    "\n",
    "print(\"Scaling applied to:\", cols_to_scale)\n",
    "print(f\"\\nScaled training data sample statistics for 'years_experience':\")\n",
    "print(f\"  Mean: {X_train_scaled['years_experience'].mean():.4f}\")\n",
    "print(f\"  Std: {X_train_scaled['years_experience'].std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-23T12:41:26.332913Z",
     "iopub.status.busy": "2026-02-23T12:41:26.332856Z",
     "iopub.status.idle": "2026-02-23T12:41:26.558143Z",
     "shell.execute_reply": "2026-02-23T12:41:26.557917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data saved to ../data/processed/\n",
      "Files:\n",
      "  - X_test.csv\n",
      "  - X_test_scaled.csv\n",
      "  - X_train.csv\n",
      "  - X_train_scaled.csv\n",
      "  - X_val.csv\n",
      "  - X_val_scaled.csv\n",
      "  - preprocessing_artifacts.joblib\n",
      "  - y_test.csv\n",
      "  - y_test_original.csv\n",
      "  - y_train.csv\n",
      "  - y_train_original.csv\n",
      "  - y_val.csv\n",
      "  - y_val_original.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Save unscaled data (for tree-based models)\n",
    "X_train.to_csv('../data/processed/X_train.csv', index=False)\n",
    "X_val.to_csv('../data/processed/X_val.csv', index=False)\n",
    "X_test.to_csv('../data/processed/X_test.csv', index=False)\n",
    "\n",
    "# Save log-scale targets (for model training)\n",
    "y_train.to_csv('../data/processed/y_train.csv', index=False)\n",
    "y_val.to_csv('../data/processed/y_val.csv', index=False)\n",
    "y_test.to_csv('../data/processed/y_test.csv', index=False)\n",
    "\n",
    "# Save original-scale targets (for evaluation in dollar terms)\n",
    "y_train_original.to_csv('../data/processed/y_train_original.csv', index=False)\n",
    "y_val_original.to_csv('../data/processed/y_val_original.csv', index=False)\n",
    "y_test_original.to_csv('../data/processed/y_test_original.csv', index=False)\n",
    "\n",
    "# Save scaled data (for linear models and MLP)\n",
    "X_train_scaled.to_csv('../data/processed/X_train_scaled.csv', index=False)\n",
    "X_val_scaled.to_csv('../data/processed/X_val_scaled.csv', index=False)\n",
    "X_test_scaled.to_csv('../data/processed/X_test_scaled.csv', index=False)\n",
    "\n",
    "# Save preprocessing artifacts\n",
    "preprocessing_artifacts = {\n",
    "    'scaler': scaler,\n",
    "    'frequent_skills': frequent_skills,\n",
    "    'experience_order': experience_order,\n",
    "    'education_order': education_order,\n",
    "    'onehot_cols': onehot_cols,\n",
    "    'feature_columns': X.columns.tolist(),\n",
    "    'cols_to_scale': cols_to_scale\n",
    "}\n",
    "\n",
    "joblib.dump(preprocessing_artifacts, '../data/processed/preprocessing_artifacts.joblib')\n",
    "\n",
    "print(\"Preprocessed data saved to ../data/processed/\")\n",
    "print(\"Files:\")\n",
    "for f in sorted(os.listdir('../data/processed')):\n",
    "    print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Preprocessing Steps Completed:\n",
    "1. **Dropped columns**: Removed identifiers and low-value features\n",
    "2. **Missing values**: Checked and handled (if any)\n",
    "3. **Outlier handling**: IQR-based winsorization on salary_usd\n",
    "4. **Log-transform**: Applied `log1p` to salary for normalized target distribution\n",
    "5. **Skills encoding**: Multi-hot encoded frequent skills (>= 2%), rare skills counted\n",
    "6. **Ordinal encoding**: experience_level (EN→EX), education_required (Associate→PhD)\n",
    "7. **One-hot encoding**: job_title, company_location, industry, employment_type, company_size, remote_ratio\n",
    "8. **Train/Val/Test split**: 70/10/20, stratified by experience_level\n",
    "9. **Scaling**: StandardScaler on numerical features (fitted on training data only)\n",
    "\n",
    "### Output:\n",
    "- Unscaled data for tree-based models (Random Forest, XGBoost, Decision Tree, Gradient Boosting)\n",
    "- Scaled data for linear models and neural networks\n",
    "- Original-scale targets for dollar-based evaluation\n",
    "- Preprocessing artifacts for inference pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
